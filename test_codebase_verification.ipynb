{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebase Verification Test Notebook\n",
    "\n",
    "This notebook verifies the structure and counts of the PPI-Inhibitors codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base path (adjust if running from different location)\n",
    "base_path = Path('.')\n",
    "code_path = base_path / 'code'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PPI-INHIBITORS CODEBASE VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Count all notebooks in repository\n",
    "all_notebooks = list(base_path.rglob('*.ipynb'))\n",
    "# Exclude hidden directories\n",
    "all_notebooks = [nb for nb in all_notebooks if not any(part.startswith('.') for part in nb.parts)]\n",
    "print(f\"\\n1. NOTEBOOK COUNT\")\n",
    "print(f\"   Total notebooks in repository: {len(all_notebooks)}\")\n",
    "for nb in sorted(all_notebooks):\n",
    "    print(f\"      - {nb}\")\n",
    "\n",
    "# 2. Count files in /code directory\n",
    "code_files = list(code_path.glob('*'))\n",
    "code_notebooks = list(code_path.glob('*.ipynb'))\n",
    "print(f\"\\n2. /CODE DIRECTORY ANALYSIS\")\n",
    "print(f\"   Total files in /code: {len(code_files)}\")\n",
    "print(f\"   Notebooks in /code: {len(code_notebooks)}\")\n",
    "for f in sorted(code_files):\n",
    "    size = os.path.getsize(f) / 1024  # KB\n",
    "    print(f\"      - {f.name:<80} ({size:>8.2f} KB)\")\n",
    "\n",
    "# 3. Analyze main GNN notebook\n",
    "main_notebook_path = code_path / 'GNN_based_pipeline_Training_for_Predicting_small_molecule_inhibition_of_protein_complexes_ipynb.ipynb'\n",
    "print(f\"\\n3. MAIN GNN NOTEBOOK ANALYSIS\")\n",
    "print(f\"   File: {main_notebook_path.name}\")\n",
    "\n",
    "if main_notebook_path.exists():\n",
    "    with open(main_notebook_path, 'r') as f:\n",
    "        notebook_data = json.load(f)\n",
    "    \n",
    "    total_cells = len(notebook_data['cells'])\n",
    "    code_cells = [cell for cell in notebook_data['cells'] if cell['cell_type'] == 'code']\n",
    "    markdown_cells = [cell for cell in notebook_data['cells'] if cell['cell_type'] == 'markdown']\n",
    "    \n",
    "    print(f\"   Total cells: {total_cells}\")\n",
    "    print(f\"   Code cells: {len(code_cells)}\")\n",
    "    print(f\"   Markdown cells: {len(markdown_cells)}\")\n",
    "    \n",
    "    # Analyze code cells\n",
    "    print(f\"\\n   Code Cell Details:\")\n",
    "    for i, cell in enumerate(code_cells):\n",
    "        source = ''.join(cell['source']) if isinstance(cell['source'], list) else cell['source']\n",
    "        lines = len(source.split('\\n'))\n",
    "        preview = source[:100].replace('\\n', ' ')[:60]\n",
    "        print(f\"      Cell {i}: {lines} lines - {preview}...\")\n",
    "else:\n",
    "    print(f\"   ERROR: Notebook not found!\")\n",
    "\n",
    "# 4. Directory structure\n",
    "print(f\"\\n4. TOP-LEVEL DIRECTORY STRUCTURE\")\n",
    "dirs = sorted([d for d in os.listdir(base_path) if os.path.isdir(base_path / d) and not d.startswith('.')])\n",
    "print(f\"   Total directories: {len(dirs)}\")\n",
    "for d in dirs:\n",
    "    dir_path = base_path / d\n",
    "    file_count = len(list(dir_path.glob('*')))\n",
    "    print(f\"      - {d:<40} ({file_count} items)\")\n",
    "\n",
    "# 5. Other notebooks analysis\n",
    "print(f\"\\n5. OTHER NOTEBOOKS IN /CODE\")\n",
    "for nb_path in sorted(code_notebooks):\n",
    "    if nb_path != main_notebook_path:\n",
    "        with open(nb_path, 'r') as f:\n",
    "            nb_data = json.load(f)\n",
    "        cells = len(nb_data['cells'])\n",
    "        print(f\"   - {nb_path.name}\")\n",
    "        print(f\"     Cells: {cells}\")\n",
    "\n",
    "# 6. Summary statistics\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Notebooks: {len(all_notebooks)}\")\n",
    "print(f\"Notebooks in /code: {len(code_notebooks)}\")\n",
    "print(f\"Main GNN notebook cells: {total_cells if main_notebook_path.exists() else 'N/A'}\")\n",
    "print(f\"Top-level directories: {len(dirs)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Results\n",
    "\n",
    "Based on the codebase analysis, the expected counts are:\n",
    "\n",
    "- **Total notebooks in repository:** 7\n",
    "- **Notebooks in /code directory:** 4\n",
    "- **Main GNN notebook total cells:** 10\n",
    "  - Code cells: 7\n",
    "  - Markdown cells: 3\n",
    "- **Top-level directories:** 8\n",
    "  - Data\n",
    "  - Features\n",
    "  - Final Results\n",
    "  - GNN-pipeline\n",
    "  - GNNbasedTrainedModels\n",
    "  - GearNet Only\n",
    "  - GearNet and GNN Trained models\n",
    "  - code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional verification: Check if specific files exist\n",
    "print(\"FILE EXISTENCE CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "important_files = [\n",
    "    'code/GNN_based_pipeline_Training_for_Predicting_small_molecule_inhibition_of_protein_complexes_ipynb.ipynb',\n",
    "    'code/GearNet Embedding.ipynb',\n",
    "    'code/seqfeaturesand_gnn_generate_prediction_gnn_with_binders_and_random_both_as_negative_ipynb.ipynb',\n",
    "    'code/svmreadfromfile_generate_prediction_binders_and_random_both_as_negative.ipynb',\n",
    "    'README.md',\n",
    "    'research_paper.pdf',\n",
    "    'Data/WriteAllexamplesRandomBindersIdsAll_24JAN_Binary.txt'\n",
    "]\n",
    "\n",
    "for file_path in important_files:\n",
    "    exists = (base_path / file_path).exists()\n",
    "    status = \"✓ EXISTS\" if exists else \"✗ MISSING\"\n",
    "    print(f\"{status}: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
